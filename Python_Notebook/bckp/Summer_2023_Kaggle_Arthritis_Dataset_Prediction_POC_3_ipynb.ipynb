{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5d_nM_9PLVt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import urllib.request"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os"
      ],
      "metadata": {
        "id": "G8xrJXnMiI21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate \\\n",
        "    \"https://github.com/ShreyaJaiswal1604/Detecting_Arthritis_X-Ray_Images/archive/refs/heads/main.zip\" \\\n",
        "    -O \"/tmp/Arthritis-dataset.zip\"\n",
        "\n",
        "\n",
        "\n",
        "zip_ref = zipfile.ZipFile('/tmp/Arthritis-dataset.zip', 'r') #Opens the zip file in read mode\n",
        "zip_ref.extractall('/tmp') #Extracts the files into the /tmp folder\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fthH7oGJiOZJ",
        "outputId": "c87da8a0-288e-4cf6-d7dc-698ded4dece7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-22 00:22:22--  https://github.com/ShreyaJaiswal1604/Detecting_Arthritis_X-Ray_Images/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/ShreyaJaiswal1604/Detecting_Arthritis_X-Ray_Images/zip/refs/heads/main [following]\n",
            "--2023-05-22 00:22:22--  https://codeload.github.com/ShreyaJaiswal1604/Detecting_Arthritis_X-Ray_Images/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.114.9\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.114.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘/tmp/Arthritis-dataset.zip’\n",
            "\n",
            "/tmp/Arthritis-data     [              <=>   ]  89.88M  31.5MB/s    in 2.8s    \n",
            "\n",
            "2023-05-22 00:22:25 (31.5 MB/s) - ‘/tmp/Arthritis-dataset.zip’ saved [94250618]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset paths\n",
        "base_dir = '/tmp/Detecting_Arthritis_X-Ray_Images-main/Image_Datasets/Original_Kaggle_Binary_Dataset'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "val_dir = os.path.join(base_dir, 'val')"
      ],
      "metadata": {
        "id": "IoFWyZ8xniGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define image data generators with data augmentation for training and normalization for validation/testing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,           # Normalize pixel values to [0, 1]\n",
        "    rotation_range=20,        # Randomly rotate images\n",
        "    width_shift_range=0.1,    # Randomly shift images horizontally\n",
        "    height_shift_range=0.1,   # Randomly shift images vertically\n",
        "    shear_range=0.1,          # Apply shear transformation\n",
        "    zoom_range=0.1,           # Apply zoom transformation\n",
        "    horizontal_flip=True,     # Flip images horizontally\n",
        "    fill_mode='nearest'       # Fill newly created pixels after rotation or shifting\n",
        ")"
      ],
      "metadata": {
        "id": "x5yNpVKkPfS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_val_datagen = ImageDataGenerator(rescale=1./255)  # Only rescale pixel values to [0, 1]\n"
      ],
      "metadata": {
        "id": "TlKUozjmYCCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define batch size and image size\n",
        "batch_size = 32\n",
        "image_size = (224, 224)"
      ],
      "metadata": {
        "id": "-A7Maz80YETF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fz9kmQ3gYGPC",
        "outputId": "e9ba96af-6cb5-4162-dbc0-e71e13bc7bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2459 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator = test_val_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoT3XMSHnzS-",
        "outputId": "be8df795-eaf8-4056-e904-ed1293f62c06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 690 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_generator = test_val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBcnO_TRnz66",
        "outputId": "15c5367a-2e8c-4803-852a-a66041de1b43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 355 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.applications.DenseNet201(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_shape=(224, 224, 3)\n",
        "    ),\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwkGd4TEn4mU",
        "outputId": "f045cae8-acbe-420e-d622-6b30fd100540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "74836368/74836368 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**CODE EXPLANATION**\n",
        "\n",
        "---\n",
        "The given code defines the architecture of a model using the Keras Sequential API. Here's an explanation of each component:\n",
        "\n",
        "tf.keras.applications.DenseNet201: This is a pre-trained DenseNet201 model provided by Keras. By setting include_top=False, we exclude the fully connected layers at the top of the network. This allows us to use the pre-trained convolutional base layers for feature extraction.\n",
        "\n",
        "**weights='imagenet':** This parameter specifies that we want to use the pre-trained weights of the DenseNet201 model that were trained on the ImageNet dataset. These weights capture general image features and can be useful for transfer learning.\n",
        "\n",
        "**input_shape=(224, 224, 3):** This defines the input shape of the model. In this case, the input shape is set to (224, 224, 3), indicating that the model expects input images of size 224x224 pixels with 3 color channels (RGB).\n",
        "\n",
        "**tf.keras.layers.GlobalAveragePooling2D():** This layer performs global average pooling on the output of the pre-trained DenseNet201 model. It reduces the spatial dimensions of the feature maps to a vector by taking the average value across each feature map. This helps to extract a compact representation of the features.\n",
        "\n",
        "**tf.keras.layers.Dense(1, activation='sigmoid'):** This is the final dense layer of the model with 1 neuron. It uses the sigmoid activation function, which maps the output to a range of [0, 1], representing the probability of the input belonging to the positive class. In this case, since it's a binary classification task (healthy or arthritis), we have a single output neuron.\n",
        "\n",
        "By combining these layers in a sequential manner, we create a model architecture that takes an input image, passes it through the pre-trained DenseNet201 base, performs global average pooling, and finally passes the result through a dense layer with sigmoid activation to obtain the output prediction.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "i52lJ1nT8oOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "XV76DZMWn8ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=5,\n",
        "    validation_data=val_generator\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOLMvmEWoCst",
        "outputId": "eec08663-6e9c-4779-e155-d2de45d75498"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "77/77 [==============================] - 3357s 42s/step - loss: 0.2160 - accuracy: 0.9215 - val_loss: 4.4592 - val_accuracy: 0.9239\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 3175s 41s/step - loss: 0.0730 - accuracy: 0.9768 - val_loss: 0.2213 - val_accuracy: 0.9183\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 3164s 41s/step - loss: 0.0493 - accuracy: 0.9829 - val_loss: 0.4178 - val_accuracy: 0.9408\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 3151s 41s/step - loss: 0.0478 - accuracy: 0.9866 - val_loss: 0.4460 - val_accuracy: 0.9437\n",
            "Epoch 5/5\n",
            "28/77 [=========>....................] - ETA: 31:51 - loss: 0.0289 - accuracy: 0.9922"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**EXPLANATION**\n",
        "\n",
        "---\n",
        "The given code is training the model using the fit method of the Keras Model class. Here's what each parameter does:\n",
        "\n",
        "**train_generator:** It is the generator that yields batches of training data, consisting of input images and their corresponding labels. It is used to train the model on the training dataset.\n",
        "\n",
        "**epochs:** It specifies the number of times the model will iterate over the entire training dataset during training. In this case, the model will be trained for 10 epochs.\n",
        "\n",
        "**validation_data:** It is the generator that yields batches of validation data, used to evaluate the model's performance on a separate dataset during training. The validation data is used to monitor the model's progress and prevent overfitting.\n",
        "\n",
        "During the training process, the model's weights and biases are updated iteratively to minimize the loss function defined in the model's compilation step. The fit method performs forward and backward propagation, calculates gradients, and updates the model parameters using an optimizer. The training process continues for the specified number of epochs, with the model gradually improving its performance on the training and validation data.\n",
        "\n",
        "\n",
        "---\n",
        "In the context of training a machine learning model, \"epochs\" refers to the number of times the model will iterate over the entire training dataset during the training process. Each epoch consists of going through the entire dataset once and updating the model's parameters based on the observed errors.\n",
        "\n",
        "When you set epochs=10 in the code, it means that the model will undergo 10 complete passes over the training dataset. In each epoch, the model will make predictions on the training data, calculate the loss (error), and adjust its internal parameters (weights and biases) based on the gradient of the loss function. By repeating this process for multiple epochs, the model learns from the data and improves its ability to make accurate predictions.\n",
        "\n",
        "The number of epochs is a hyperparameter that needs to be carefully chosen. **Too few epochs may result in underfitting, where the model fails to capture the underlying patterns in the data. On the other hand, too many epochs may lead to overfitting, where the model becomes overly specialized to the training data and performs poorly on unseen data. The optimal number of epochs can vary depending on the complexity of the problem and the size of the dataset, and it often requires experimentation and validation on a separate validation set.**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pzTnx7odxKC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "pXdkbyxHoF5D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f41e9ee4-2565-419e-e2c1-493bedcf6b6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/22 [==============================] - 155s 7s/step - loss: 0.8383 - accuracy: 0.8797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the true labels for the test set\n",
        "y_true = test_generator.classes"
      ],
      "metadata": {
        "id": "3UHUXAT6qs9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "y_pred_prob = model.predict(test_generator)\n",
        "y_pred = np.round(y_pred_prob).flatten()"
      ],
      "metadata": {
        "id": "G1_KfLR7qs24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)"
      ],
      "metadata": {
        "id": "ksSyZv8WrDRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the confusion matrix\n",
        "import seaborn as sns\n",
        "\n",
        "labels = ['Healthy', 'Arthritis']\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OQCNDQb1rP6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**REFERENCES**\n",
        "\n",
        "---\n",
        "https://towardsdatascience.com/an-informative-colab-guide-to-load-image-datasets-from-github-kaggle-and-local-machine-75cae89ffa1e\n",
        "\n",
        "https://pyimagesearch.com/2020/03/16/detecting-covid-19-in-x-ray-images-with-keras-tensorflow-and-deep-learning/"
      ],
      "metadata": {
        "id": "WyAuVhDyTP8t"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BgsgSqRerQyI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}